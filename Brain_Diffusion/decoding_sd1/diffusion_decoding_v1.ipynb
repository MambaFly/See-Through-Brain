{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac01e9e-fbd5-4fd3-a3ea-9a54a7550c94",
   "metadata": {},
   "source": [
    "# 使用扩散模型对大脑解码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf229559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录: /data/zlhu/NeuroAI/Eye-of-Brain/Brain-Diffusion\n",
      "当前工作目录: /data/zlhu/NeuroAI/Eye-of-Brain/Brain-Diffusion/encoding\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 获取当前文件所在目录\n",
    "current_dir = os.path.dirname(os.path.abspath(''))\n",
    "print(\"当前工作目录:\", current_dir)\n",
    "# 设置工作目录\n",
    "os.chdir('/data/zlhu/NeuroAI/Eye-of-Brain/Brain-Diffusion/encoding')\n",
    "# 验证工作目录\n",
    "print(\"当前工作目录:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e99221c-dbcf-4fe0-8aa4-9cf47b36802d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:58:38.076724Z",
     "iopub.status.busy": "2024-11-27T01:58:38.076131Z",
     "iopub.status.idle": "2024-11-27T01:58:38.094574Z",
     "shell.execute_reply": "2024-11-27T01:58:38.092780Z",
     "shell.execute_reply.started": "2024-11-27T01:58:38.076678Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "from PIL import Image\n",
    "import scipy.io\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import trange\n",
    "from einops import rearrange\n",
    "from torch import autocast\n",
    "from contextlib import nullcontext\n",
    "from pytorch_lightning import seed_everything\n",
    "import sys\n",
    "from nsd_access.nsda import NSDAccess\n",
    "from ldm.util import instantiate_from_config\n",
    "from ldm.models.diffusion.ddim import DDIMSampler\n",
    "# from ldm.data.util import AddMiDaS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22bfca36-a6a5-4e87-8307-42ae990203fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:58:38.346058Z",
     "iopub.status.busy": "2024-11-27T01:58:38.345545Z",
     "iopub.status.idle": "2024-11-27T01:58:38.357891Z",
     "shell.execute_reply": "2024-11-27T01:58:38.356047Z",
     "shell.execute_reply.started": "2024-11-27T01:58:38.346016Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_from_config(config, ckpt, gpu, verbose=False):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    if \"global_step\" in pl_sd:\n",
    "        print(f\"Global Step: {pl_sd['global_step']}\")\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    if len(m) > 0 and verbose:\n",
    "        print(\"missing keys:\")\n",
    "        print(m)\n",
    "    if len(u) > 0 and verbose:\n",
    "        print(\"unexpected keys:\")\n",
    "        print(u)\n",
    "    model.cuda(f\"cuda:{gpu}\")\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7157c37-1262-4b62-a6a4-1d796b884324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:58:38.770719Z",
     "iopub.status.busy": "2024-11-27T01:58:38.770227Z",
     "iopub.status.idle": "2024-11-27T01:58:38.780784Z",
     "shell.execute_reply": "2024-11-27T01:58:38.778989Z",
     "shell.execute_reply.started": "2024-11-27T01:58:38.770680Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_img_from_arr(img_arr):\n",
    "    image = Image.fromarray(img_arr).convert(\"RGB\")\n",
    "    w, h = 512, 512\n",
    "    image = image.resize((w, h), resample=PIL.Image.LANCZOS)\n",
    "    image = np.array(image).astype(np.float32) / 255.0\n",
    "    image = image[None].transpose(0, 3, 1, 2)\n",
    "    image = torch.from_numpy(image)\n",
    "    return 2.*image - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbe3de9e-0f1a-4e09-98c4-2532e4cc8927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:58:40.210097Z",
     "iopub.status.busy": "2024-11-27T01:58:40.209487Z",
     "iopub.status.idle": "2024-11-27T01:58:40.226599Z",
     "shell.execute_reply": "2024-11-27T01:58:40.225123Z",
     "shell.execute_reply.started": "2024-11-27T01:58:40.210054Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "seed = 42\n",
    "seed_everything(seed)\n",
    "imgidx = 0\n",
    "gpu = 0\n",
    "method = \"text\"\n",
    "subject= \"subj07\"\n",
    "# gandir = f'../data/decoded/gan_recon_img/all_layers/{subject}/streams/'\n",
    "captdir = f'../../Brain-Caption/decoded_captions/{subject}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9300b78d-fdd0-441f-b27c-52dad49a4b04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:58:40.698261Z",
     "iopub.status.busy": "2024-11-27T01:58:40.697626Z",
     "iopub.status.idle": "2024-11-27T01:58:40.721834Z",
     "shell.execute_reply": "2024-11-27T01:58:40.720714Z",
     "shell.execute_reply.started": "2024-11-27T01:58:40.698217Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load NSD information\n",
    "nsd_expdesign = scipy.io.loadmat('../data/nsd/nsddata/experiments/nsd/nsd_expdesign.mat')\n",
    "\n",
    "# Note that mos of them are 1-base index!\n",
    "# This is why I subtract 1\n",
    "sharedix = nsd_expdesign['sharedix'] -1 \n",
    "\n",
    "nsda = NSDAccess('../data/nsd/')\n",
    "sf = h5py.File(nsda.stimuli_file, 'r')\n",
    "sdataset = sf.get('imgBrick')\n",
    "\n",
    "stims_ave = np.load(f'../data/stim/{subject}/{subject}_stims_ave.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "288d77ab-e71f-47ed-be9c-c705f733cdb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:58:44.953750Z",
     "iopub.status.busy": "2024-11-27T01:58:44.953054Z",
     "iopub.status.idle": "2024-11-27T01:58:45.008405Z",
     "shell.execute_reply": "2024-11-27T01:58:45.007751Z",
     "shell.execute_reply.started": "2024-11-27T01:58:44.953700Z"
    }
   },
   "outputs": [],
   "source": [
    "tr_idx = np.zeros_like(stims_ave)\n",
    "for idx, s in enumerate(stims_ave):\n",
    "    if s in sharedix:\n",
    "        tr_idx[idx] = 0\n",
    "    else:\n",
    "        tr_idx[idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62778084-87d4-4189-a530-31a50551cc45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:36:14.294067Z",
     "iopub.status.busy": "2024-11-27T01:36:14.293567Z",
     "iopub.status.idle": "2024-11-27T01:39:50.425588Z",
     "shell.execute_reply": "2024-11-27T01:39:50.424839Z",
     "shell.execute_reply.started": "2024-11-27T01:36:14.294026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../stable-diffusion_v1/models/ldm/stable-diffusion-v1/v1-5-pruned-emaonly.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55633/215837999.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pl_sd = torch.load(ckpt, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step: 840000\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    }
   ],
   "source": [
    "# Load Stable Diffusion Model\n",
    "config = '../stable-diffusion_v1/configs/stable-diffusion/v1-inference.yaml'\n",
    "ckpt = '../stable-diffusion_v1/models/ldm/stable-diffusion-v1/sd-v1-4.ckpt'\n",
    "ckpt = '../stable-diffusion_v1/models/ldm/stable-diffusion-v1/v1-5-pruned-emaonly.ckpt'\n",
    "config = OmegaConf.load(f\"{config}\")\n",
    "torch.cuda.set_device(gpu)\n",
    "model = load_model_from_config(config, f\"{ckpt}\", gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebe295a5-a934-4161-929d-8b92ddaa62ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:58:50.898998Z",
     "iopub.status.busy": "2024-11-27T01:58:50.898348Z",
     "iopub.status.idle": "2024-11-27T01:58:50.908067Z",
     "shell.execute_reply": "2024-11-27T01:58:50.906314Z",
     "shell.execute_reply.started": "2024-11-27T01:58:50.898952Z"
    }
   },
   "outputs": [],
   "source": [
    "n_samples = 1\n",
    "ddim_steps = 50\n",
    "ddim_eta = 0.0\n",
    "strength = 0.8\n",
    "scale = 5.0\n",
    "n_iter = 5\n",
    "precision = 'autocast'\n",
    "precision_scope = autocast if precision == \"autocast\" else nullcontext\n",
    "batch_size = n_samples\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55a22778-ab30-4da6-998f-f9daf7af4257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:58:52.700159Z",
     "iopub.status.busy": "2024-11-27T01:58:52.699507Z",
     "iopub.status.idle": "2024-11-27T01:58:52.861720Z",
     "shell.execute_reply": "2024-11-27T01:58:52.860455Z",
     "shell.execute_reply.started": "2024-11-27T01:58:52.700111Z"
    }
   },
   "outputs": [],
   "source": [
    "# 解码结果输出路径\n",
    "outdir = f'../data/output/image-{method}/{subject}/'\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "sample_path = os.path.join(outdir, f\"samples\")\n",
    "os.makedirs(sample_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96312a5c-25ce-4dc8-9602-39b9570f2667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:58:53.163038Z",
     "iopub.status.busy": "2024-11-27T01:58:53.162422Z",
     "iopub.status.idle": "2024-11-27T01:58:53.211837Z",
     "shell.execute_reply": "2024-11-27T01:58:53.210960Z",
     "shell.execute_reply.started": "2024-11-27T01:58:53.162995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target t_enc is 40 steps\n"
     ]
    }
   ],
   "source": [
    "precision = 'autocast'\n",
    "device = torch.device(f\"cuda:{gpu}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "sampler = DDIMSampler(model)\n",
    "\n",
    "sampler.make_schedule(ddim_num_steps=ddim_steps, ddim_eta=ddim_eta, verbose=False)\n",
    "\n",
    "assert 0. <= strength <= 1., 'can only work with strength in [0.0, 1.0]'\n",
    "t_enc = int(strength * ddim_steps)\n",
    "print(f\"target t_enc is {t_enc} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "166c7006-ae69-490f-bee5-6218d657844f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:59:17.460922Z",
     "iopub.status.busy": "2024-11-27T01:59:17.460206Z",
     "iopub.status.idle": "2024-11-27T01:59:17.853951Z",
     "shell.execute_reply": "2024-11-27T01:59:17.853377Z",
     "shell.execute_reply.started": "2024-11-27T01:59:17.460871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load z (Image)\n",
    "imgidx_te = np.where(tr_idx==0)[0][imgidx] # Extract test image index\n",
    "idx73k= stims_ave[imgidx_te]\n",
    "Image.fromarray(np.squeeze(sdataset[idx73k,:,:,:]).astype(np.uint8)).save(\n",
    "    os.path.join(sample_path, f\"{imgidx:05}_org.png\"))    \n",
    "\n",
    "if method in ['init','text']:\n",
    "    roi_latent = 'early'\n",
    "    init_latent = np.load(f'../data/decoded/{subject}/{subject}_{roi_latent}_brain_embs_init_latent.npy')\n",
    "    imgarr = torch.Tensor(init_latent[imgidx,:].reshape(4,40,40)).unsqueeze(0).to('cuda')\n",
    "\n",
    "    # Generate image from Z\n",
    "    precision_scope = autocast if precision == \"autocast\" else nullcontext\n",
    "    with torch.no_grad():\n",
    "        with precision_scope(\"cuda\"):\n",
    "            with model.ema_scope():\n",
    "                x_samples = model.decode_first_stage(imgarr)\n",
    "                x_samples = torch.clamp((x_samples + 1.0) / 2.0, min=0.0, max=1.0)\n",
    "\n",
    "                for x_sample in x_samples:\n",
    "                    x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')\n",
    "    im = Image.fromarray(x_sample.astype(np.uint8)).resize((512,512))\n",
    "    im = np.array(im)\n",
    "\n",
    "elif method == 'gan':\n",
    "    ganpath = f'{gandir}/recon_image_normalized-VGG19-fc8-{subject}-streams-{imgidx:06}.tiff'\n",
    "    im = Image.open(ganpath).resize((512,512))\n",
    "    im = np.array(im)\n",
    "\n",
    "init_image = load_img_from_arr(im).to('cuda')\n",
    "init_latent = model.get_first_stage_encoding(model.encode_first_stage(init_image))  # move to latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bafd2df-d19d-490b-9253-7b80d6f51db3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:59:19.260528Z",
     "iopub.status.busy": "2024-11-27T01:59:19.259781Z",
     "iopub.status.idle": "2024-11-27T01:59:20.368112Z",
     "shell.execute_reply": "2024-11-27T01:59:20.366606Z",
     "shell.execute_reply.started": "2024-11-27T01:59:19.260477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load c (Semantics)\n",
    "if method == 'init':\n",
    "    roi_c = 'ventral'\n",
    "    c_embs = np.load(f'../data/decoded/{subject}/{subject}_{roi_c}_brain_embs_c.npy')\n",
    "    carr = c_embs[imgidx,:].reshape(77,768)\n",
    "    c = torch.Tensor(carr).unsqueeze(0).to('cuda')\n",
    "elif method in ['text','gan']:\n",
    "    captions = pd.read_csv(f'{captdir}/captions_brain.csv', sep='\\t',header=None)\n",
    "    c = model.get_learned_conditioning(captions.iloc[imgidx][0]).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4ef367f-a67b-4b9d-b537-31a10946cfc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:59:22.155466Z",
     "iopub.status.busy": "2024-11-27T01:59:22.154888Z",
     "iopub.status.idle": "2024-11-27T01:59:22.169542Z",
     "shell.execute_reply": "2024-11-27T01:59:22.168142Z",
     "shell.execute_reply.started": "2024-11-27T01:59:22.155422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 77, 768])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5e2b295-fc86-4cfe-b8a8-1c5a57074523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:59:22.922157Z",
     "iopub.status.busy": "2024-11-27T01:59:22.921648Z",
     "iopub.status.idle": "2024-11-27T01:59:22.946429Z",
     "shell.execute_reply": "2024-11-27T01:59:22.945409Z",
     "shell.execute_reply.started": "2024-11-27T01:59:22.922116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 77, 768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uc = model.get_learned_conditioning(batch_size * [\"\"])\n",
    "uc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "009430fb-496f-4c20-8fe5-ecf62431092a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:59:40.185451Z",
     "iopub.status.busy": "2024-11-27T01:59:40.184877Z",
     "iopub.status.idle": "2024-11-27T02:01:07.614192Z",
     "shell.execute_reply": "2024-11-27T02:01:07.613607Z",
     "shell.execute_reply.started": "2024-11-27T01:59:40.185407Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling:   0%|                                          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding image: 100%|██████████████████████████| 40/40 [00:16<00:00,  2.39it/s]\n",
      "Sampling:  20%|██████▊                           | 1/5 [00:17<01:08, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding image: 100%|██████████████████████████| 40/40 [00:16<00:00,  2.38it/s]\n",
      "Sampling:  40%|█████████████▌                    | 2/5 [00:34<00:51, 17.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding image: 100%|██████████████████████████| 40/40 [00:16<00:00,  2.37it/s]\n",
      "Sampling:  60%|████████████████████▍             | 3/5 [00:51<00:34, 17.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding image: 100%|██████████████████████████| 40/40 [00:16<00:00,  2.36it/s]\n",
      "Sampling:  80%|███████████████████████████▏      | 4/5 [01:08<00:17, 17.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding image: 100%|██████████████████████████| 40/40 [00:16<00:00,  2.36it/s]\n",
      "Sampling: 100%|██████████████████████████████████| 5/5 [01:26<00:00, 17.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate image from Z (image) + C (semantics)\n",
    "base_count = 0\n",
    "with torch.no_grad():\n",
    "    with precision_scope(\"cuda\"):\n",
    "        with model.ema_scope():\n",
    "            for n in trange(n_iter, desc=\"Sampling\"):\n",
    "                uc = model.get_learned_conditioning(batch_size * [\"\"])\n",
    "\n",
    "                # encode (scaled latent)\n",
    "                z_enc = sampler.stochastic_encode(init_latent, torch.tensor([t_enc]*batch_size).to(device))\n",
    "                # decode it\n",
    "                samples = sampler.decode(z_enc, c, t_enc, unconditional_guidance_scale=scale,\n",
    "                                        unconditional_conditioning=uc,)\n",
    "                \n",
    "                x_samples = model.decode_first_stage(samples)\n",
    "                x_samples = torch.clamp((x_samples + 1.0) / 2.0, min=0.0, max=1.0)\n",
    "\n",
    "                for x_sample in x_samples:\n",
    "                    x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')\n",
    "                Image.fromarray(x_sample.astype(np.uint8)).save(\n",
    "                    os.path.join(sample_path, f\"{imgidx:05}_{base_count:03}.png\"))    \n",
    "                base_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "ldm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
